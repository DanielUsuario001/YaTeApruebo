"""
Servicio de integraci√≥n con OpenAI API.
Maneja las comunicaciones con los modelos de IA.
"""

import asyncio
from typing import Dict, Optional, List
import openai
from openai import AsyncOpenAI

from config.settings import settings
from loguru import logger

class OpenAIService:
    """
    Servicio para interactuar con la API de OpenAI.
    
    Proporciona m√©todos para generar respuestas usando diferentes modelos
    y configuraciones seg√∫n el agente que lo utilice.
    """
    
    def __init__(self, api_key: str):
        """
        Inicializa el servicio de OpenAI.
        
        Args:
            api_key: Clave API de OpenAI
        """
        self.api_key = api_key
        self.client = AsyncOpenAI(api_key=api_key)
        self.model = settings.OPENAI_MODEL
        self.max_tokens = settings.MAX_TOKENS
        self.temperature = settings.TEMPERATURE
        
        logger.info("ü§ñ Servicio OpenAI inicializado")
    
    async def generar_respuesta(
        self, 
        prompt: str, 
        system_message: Optional[str] = None,
        model: Optional[str] = None,
        max_tokens: Optional[int] = None,
        temperature: Optional[float] = None
    ) -> str:
        """
        Genera una respuesta usando OpenAI.
        
        Args:
            prompt: Mensaje principal para el modelo
            system_message: Mensaje de sistema (opcional)
            model: Modelo espec√≠fico a usar (opcional)
            max_tokens: N√∫mero m√°ximo de tokens (opcional)
            temperature: Temperatura para la generaci√≥n (opcional)
            
        Returns:
            Respuesta generada por el modelo
            
        Raises:
            Exception: Si hay error en la comunicaci√≥n con OpenAI
        """
        try:
            # Usar par√°metros por defecto si no se especifican
            model_to_use = model or self.model
            max_tokens_to_use = max_tokens or self.max_tokens
            temperature_to_use = temperature or self.temperature
            
            # Preparar mensajes
            messages = []
            
            if system_message:
                messages.append({
                    "role": "system",
                    "content": system_message
                })
            
            messages.append({
                "role": "user",
                "content": prompt
            })
            
            logger.debug(f"üì§ Enviando petici√≥n a OpenAI - Modelo: {model_to_use}")
            
            # Realizar petici√≥n a OpenAI
            response = await self.client.chat.completions.create(
                model=model_to_use,
                messages=messages,
                max_tokens=max_tokens_to_use,
                temperature=temperature_to_use,
                top_p=1,
                frequency_penalty=0,
                presence_penalty=0
            )
            
            # Extraer respuesta
            if response.choices and len(response.choices) > 0:
                content = response.choices[0].message.content
                
                logger.debug(f"üì• Respuesta recibida de OpenAI ({len(content)} caracteres)")
                
                return content.strip()
            else:
                raise Exception("No se recibi√≥ respuesta v√°lida de OpenAI")
                
        except openai.RateLimitError as e:
            logger.error(f"‚ùå L√≠mite de rate alcanzado en OpenAI: {str(e)}")
            raise Exception("L√≠mite de uso de API alcanzado. Intenta m√°s tarde.")
            
        except openai.AuthenticationError as e:
            logger.error(f"‚ùå Error de autenticaci√≥n en OpenAI: {str(e)}")
            raise Exception("Error de autenticaci√≥n con OpenAI API")
            
        except openai.APIError as e:
            logger.error(f"‚ùå Error de API de OpenAI: {str(e)}")
            raise Exception(f"Error en API de OpenAI: {str(e)}")
            
        except Exception as e:
            logger.error(f"‚ùå Error inesperado en OpenAI: {str(e)}")
            raise Exception(f"Error en comunicaci√≥n con OpenAI: {str(e)}")
    
    async def generar_respuesta_streaming(
        self, 
        prompt: str, 
        system_message: Optional[str] = None,
        callback = None
    ) -> str:
        """
        Genera una respuesta en modo streaming (para respuestas largas).
        
        Args:
            prompt: Mensaje principal
            system_message: Mensaje de sistema (opcional)
            callback: Funci√≥n callback para procesar chunks (opcional)
            
        Returns:
            Respuesta completa generada
        """
        try:
            messages = []
            
            if system_message:
                messages.append({
                    "role": "system",
                    "content": system_message
                })
            
            messages.append({
                "role": "user",
                "content": prompt
            })
            
            logger.debug("üì§ Iniciando streaming de OpenAI")
            
            full_response = ""
            
            stream = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                stream=True
            )
            
            async for chunk in stream:
                if chunk.choices[0].delta.content is not None:
                    content_chunk = chunk.choices[0].delta.content
                    full_response += content_chunk
                    
                    # Llamar callback si est√° disponible
                    if callback:
                        await callback(content_chunk)
            
            logger.debug(f"üì• Streaming completado ({len(full_response)} caracteres)")
            
            return full_response.strip()
            
        except Exception as e:
            logger.error(f"‚ùå Error en streaming de OpenAI: {str(e)}")
            raise Exception(f"Error en streaming: {str(e)}")
    
    async def analizar_documento_con_contexto(
        self, 
        contenido_documento: str,
        contexto_empresa: Dict,
        tipo_analisis: str
    ) -> str:
        """
        Realiza an√°lisis especializado de documentos con contexto empresarial.
        
        Args:
            contenido_documento: Contenido del documento a analizar
            contexto_empresa: Informaci√≥n contextual de la empresa
            tipo_analisis: Tipo de an√°lisis a realizar
            
        Returns:
            An√°lisis especializado del documento
        """
        system_message = f"""
        Eres un analista financiero senior especializado en {tipo_analisis}.
        
        Informaci√≥n del contexto:
        - Empresa: {contexto_empresa.get('nombre', 'N/A')}
        - Sector: {contexto_empresa.get('sector', 'N/A')}
        - Fecha: {contexto_empresa.get('fecha', 'N/A')}
        
        Tu an√°lisis debe ser:
        1. T√©cnicamente riguroso
        2. Espec√≠fico para el sector
        3. Orientado a la evaluaci√≥n de riesgos
        4. Basado en mejores pr√°cticas financieras
        5. Claro y accionable
        
        Proporciona siempre conclusiones num√©ricas cuando sea posible.
        """
        
        prompt = f"""
        Analiza el siguiente documento financiero para {tipo_analisis}:
        
        DOCUMENTO:
        {contenido_documento}
        
        Proporciona un an√°lisis detallado que incluya:
        1. Indicadores clave calculados
        2. Interpretaci√≥n de los resultados
        3. Comparaci√≥n con est√°ndares del sector
        4. Identificaci√≥n de riesgos y oportunidades
        5. Recomendaciones espec√≠ficas
        
        Estructura tu respuesta de manera profesional y utiliza formato JSON para datos num√©ricos.
        """
        
        return await self.generar_respuesta(
            prompt=prompt,
            system_message=system_message,
            temperature=0.1  # Menos creatividad para an√°lisis financieros
        )
    
    async def validar_conexion(self) -> Dict:
        """
        Valida que la conexi√≥n con OpenAI est√© funcionando.
        
        Returns:
            Dict con resultado de la validaci√≥n
        """
        try:
            # Hacer una petici√≥n simple de prueba
            test_response = await self.generar_respuesta(
                prompt="Responde solo con 'OK' si recibes este mensaje.",
                max_tokens=10
            )
            
            if "OK" in test_response:
                logger.info("‚úÖ Conexi√≥n con OpenAI validada correctamente")
                return {
                    "valid": True,
                    "message": "Conexi√≥n exitosa",
                    "model": self.model
                }
            else:
                return {
                    "valid": False,
                    "message": "Respuesta inesperada en validaci√≥n"
                }
                
        except Exception as e:
            logger.error(f"‚ùå Error validando conexi√≥n OpenAI: {str(e)}")
            return {
                "valid": False,
                "message": f"Error de conexi√≥n: {str(e)}"
            }
    
    def cambiar_configuracion(
        self, 
        model: Optional[str] = None,
        max_tokens: Optional[int] = None,
        temperature: Optional[float] = None
    ) -> None:
        """
        Cambia la configuraci√≥n del servicio OpenAI.
        
        Args:
            model: Nuevo modelo a usar
            max_tokens: Nuevos tokens m√°ximos
            temperature: Nueva temperatura
        """
        if model:
            self.model = model
            logger.info(f"üîÑ Modelo cambiado a: {model}")
        
        if max_tokens:
            self.max_tokens = max_tokens
            logger.info(f"üîÑ Max tokens cambiado a: {max_tokens}")
        
        if temperature is not None:
            self.temperature = temperature
            logger.info(f"üîÑ Temperature cambiada a: {temperature}")
    
    def obtener_estadisticas_uso(self) -> Dict:
        """
        Obtiene estad√≠sticas b√°sicas de uso del servicio.
        
        Returns:
            Dict con estad√≠sticas de uso
        """
        return {
            "model_actual": self.model,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature,
            "api_key_configurada": bool(self.api_key)
        }